name: interview-analytics-agent

services:
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-interview}
      POSTGRES_USER: ${POSTGRES_USER:-interview}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-interview}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-interview} -d ${POSTGRES_DB:-interview}"]
      interval: 5s
      timeout: 3s
      retries: 20
    volumes:
      - pg_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    command: ["redis-server", "--appendonly", "yes"]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 20
    volumes:
      - redis_data:/data

  migrate:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      POSTGRES_DSN: ${POSTGRES_DSN:-postgresql+psycopg://interview:interview@postgres:5432/interview}
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      LOG_FORMAT: ${LOG_FORMAT:-json}
    command: ["alembic", "upgrade", "head"]
    restart: "no"

  api-gateway:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      migrate:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      POSTGRES_DSN: ${POSTGRES_DSN:-postgresql+psycopg://interview:interview@postgres:5432/interview}
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      STORAGE_MODE: ${STORAGE_MODE:-local_fs}
      CHUNKS_DIR: ${CHUNKS_DIR:-/data/chunks}
      STORAGE_SHARED_FS_DIR: ${STORAGE_SHARED_FS_DIR:-}
      STORAGE_REQUIRE_SHARED_IN_PROD: ${STORAGE_REQUIRE_SHARED_IN_PROD:-true}
      AUTH_MODE: ${AUTH_MODE:-none}
      API_KEYS: ${API_KEYS:-}
      SERVICE_API_KEYS: ${SERVICE_API_KEYS:-}
      ALLOW_SERVICE_API_KEY_IN_JWT_MODE: ${ALLOW_SERVICE_API_KEY_IN_JWT_MODE:-true}
      OIDC_ISSUER_URL: ${OIDC_ISSUER_URL:-}
      OIDC_JWKS_URL: ${OIDC_JWKS_URL:-}
      OIDC_AUDIENCE: ${OIDC_AUDIENCE:-}
      OIDC_ALGORITHMS: ${OIDC_ALGORITHMS:-RS256}
      JWT_SHARED_SECRET: ${JWT_SHARED_SECRET:-}
      MEETING_CONNECTOR_PROVIDER: ${MEETING_CONNECTOR_PROVIDER:-sberjazz_mock}
      MEETING_AUTO_JOIN_ON_START: ${MEETING_AUTO_JOIN_ON_START:-false}
      SBERJAZZ_API_BASE: ${SBERJAZZ_API_BASE:-}
      SBERJAZZ_API_TOKEN: ${SBERJAZZ_API_TOKEN:-}
      SBERJAZZ_TIMEOUT_SEC: ${SBERJAZZ_TIMEOUT_SEC:-10}
      SBERJAZZ_HTTP_RETRIES: ${SBERJAZZ_HTTP_RETRIES:-2}
      SBERJAZZ_HTTP_RETRY_BACKOFF_MS: ${SBERJAZZ_HTTP_RETRY_BACKOFF_MS:-300}
      SBERJAZZ_HTTP_RETRY_STATUSES: ${SBERJAZZ_HTTP_RETRY_STATUSES:-408,409,425,429,500,502,503,504}
      SBERJAZZ_RETRIES: ${SBERJAZZ_RETRIES:-2}
      SBERJAZZ_RETRY_BACKOFF_MS: ${SBERJAZZ_RETRY_BACKOFF_MS:-300}
      SBERJAZZ_CB_FAILURE_THRESHOLD: ${SBERJAZZ_CB_FAILURE_THRESHOLD:-5}
      SBERJAZZ_CB_OPEN_SEC: ${SBERJAZZ_CB_OPEN_SEC:-60}
      SBERJAZZ_OP_LOCK_TTL_SEC: ${SBERJAZZ_OP_LOCK_TTL_SEC:-60}
      SBERJAZZ_CB_AUTO_RESET_ENABLED: ${SBERJAZZ_CB_AUTO_RESET_ENABLED:-true}
      SBERJAZZ_CB_AUTO_RESET_MIN_AGE_SEC: ${SBERJAZZ_CB_AUTO_RESET_MIN_AGE_SEC:-30}
      SBERJAZZ_SESSION_TTL_SEC: ${SBERJAZZ_SESSION_TTL_SEC:-86400}
      SBERJAZZ_RECONCILE_STALE_SEC: ${SBERJAZZ_RECONCILE_STALE_SEC:-900}
      SBERJAZZ_MOCK_LIVE_CHUNKS_B64: ${SBERJAZZ_MOCK_LIVE_CHUNKS_B64:-}
      LLM_ENABLED: ${LLM_ENABLED:-false}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      LOG_FORMAT: ${LOG_FORMAT:-json}
    command: ["uvicorn", "apps.api_gateway.main:app", "--host", "0.0.0.0", "--port", "8010"]
    ports:
      - "8010:8010"
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8010/health >/dev/null || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 30
    volumes:
      - app_data:/data
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped


  stt-model-init:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      # Куда складываем HF cache (модель и файлы)
      HF_HOME: /hf
      HF_HUB_CACHE: /hf/hub
      # init должен иметь право скачать (offline выключен)
      HF_HUB_OFFLINE: "0"

      # параметры модели (берём те же, что и worker-stt)
      WHISPER_MODEL_SIZE: ${WHISPER_MODEL_SIZE:-small}
      WHISPER_DEVICE: ${WHISPER_DEVICE:-cpu}
      WHISPER_COMPUTE_TYPE: ${WHISPER_COMPUTE_TYPE:-int8}

      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      LOG_FORMAT: ${LOG_FORMAT:-json}
    volumes:
      - hf_cache:/hf
    command:
      - python3
      - -c
      - >
          import os;
          from faster_whisper import WhisperModel;
          m=os.environ.get("WHISPER_MODEL_SIZE","small");
          d=os.environ.get("WHISPER_DEVICE","cpu");
          c=os.environ.get("WHISPER_COMPUTE_TYPE","int8");
          WhisperModel(m, device=d, compute_type=c);
          print("STT model cached:", m, d, c)
    restart: "no"

  worker-stt:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      stt-model-init:
        condition: service_completed_successfully
      migrate:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      POSTGRES_DSN: ${POSTGRES_DSN:-postgresql+psycopg://interview:interview@postgres:5432/interview}
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      STORAGE_MODE: ${STORAGE_MODE:-local_fs}
      CHUNKS_DIR: ${CHUNKS_DIR:-/data/chunks}
      STORAGE_SHARED_FS_DIR: ${STORAGE_SHARED_FS_DIR:-}
      STORAGE_REQUIRE_SHARED_IN_PROD: ${STORAGE_REQUIRE_SHARED_IN_PROD:-true}
      STT_PROVIDER: ${STT_PROVIDER:-whisper_local}
      WHISPER_MODEL_SIZE: ${WHISPER_MODEL_SIZE:-small}
      WHISPER_DEVICE: ${WHISPER_DEVICE:-cpu}
      WHISPER_COMPUTE_TYPE: ${WHISPER_COMPUTE_TYPE:-int8}
      WHISPER_LANGUAGE: ${WHISPER_LANGUAGE:-ru}
      WHISPER_VAD_FILTER: ${WHISPER_VAD_FILTER:-true}
      WHISPER_BEAM_SIZE: ${WHISPER_BEAM_SIZE:-1}
      HF_HOME: /hf
      HF_HUB_CACHE: /hf/hub
      HF_HUB_OFFLINE: "1"
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      LOG_FORMAT: ${LOG_FORMAT:-json}
    command: ["python3", "-m", "apps.worker_stt.main"]
    volumes:
      - app_data:/data
      - hf_cache:/hf
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped

  worker-enhancer:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      migrate:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      POSTGRES_DSN: ${POSTGRES_DSN:-postgresql+psycopg://interview:interview@postgres:5432/interview}
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      CHUNKS_DIR: ${CHUNKS_DIR:-/data/chunks}
      LLM_ENABLED: ${LLM_ENABLED:-false}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      LOG_FORMAT: ${LOG_FORMAT:-json}
    command: ["python3", "-m", "apps.worker_enhancer.main"]
    volumes:
      - app_data:/data
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped

  worker-analytics:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      migrate:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      POSTGRES_DSN: ${POSTGRES_DSN:-postgresql+psycopg://interview:interview@postgres:5432/interview}
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      CHUNKS_DIR: ${CHUNKS_DIR:-/data/chunks}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      LOG_FORMAT: ${LOG_FORMAT:-json}
    command: ["python3", "-m", "apps.worker_analytics.main"]
    volumes:
      - app_data:/data
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped

  worker-delivery:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      migrate:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      POSTGRES_DSN: ${POSTGRES_DSN:-postgresql+psycopg://interview:interview@postgres:5432/interview}
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      CHUNKS_DIR: ${CHUNKS_DIR:-/data/chunks}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      LOG_FORMAT: ${LOG_FORMAT:-json}
    command: ["python3", "-m", "apps.worker_delivery.main"]
    volumes:
      - app_data:/data
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped

  worker-retention:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      migrate:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      POSTGRES_DSN: ${POSTGRES_DSN:-postgresql+psycopg://interview:interview@postgres:5432/interview}
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      CHUNKS_DIR: ${CHUNKS_DIR:-/data/chunks}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      LOG_FORMAT: ${LOG_FORMAT:-json}
    command: ["python3", "-m", "apps.worker_retention.main"]
    volumes:
      - app_data:/data
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped

  worker-reconciliation:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      migrate:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      POSTGRES_DSN: ${POSTGRES_DSN:-postgresql+psycopg://interview:interview@postgres:5432/interview}
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      MEETING_CONNECTOR_PROVIDER: ${MEETING_CONNECTOR_PROVIDER:-sberjazz_mock}
      SBERJAZZ_API_BASE: ${SBERJAZZ_API_BASE:-}
      SBERJAZZ_API_TOKEN: ${SBERJAZZ_API_TOKEN:-}
      SBERJAZZ_TIMEOUT_SEC: ${SBERJAZZ_TIMEOUT_SEC:-10}
      SBERJAZZ_HTTP_RETRIES: ${SBERJAZZ_HTTP_RETRIES:-2}
      SBERJAZZ_HTTP_RETRY_BACKOFF_MS: ${SBERJAZZ_HTTP_RETRY_BACKOFF_MS:-300}
      SBERJAZZ_HTTP_RETRY_STATUSES: ${SBERJAZZ_HTTP_RETRY_STATUSES:-408,409,425,429,500,502,503,504}
      SBERJAZZ_RETRIES: ${SBERJAZZ_RETRIES:-2}
      SBERJAZZ_RETRY_BACKOFF_MS: ${SBERJAZZ_RETRY_BACKOFF_MS:-300}
      SBERJAZZ_CB_FAILURE_THRESHOLD: ${SBERJAZZ_CB_FAILURE_THRESHOLD:-5}
      SBERJAZZ_CB_OPEN_SEC: ${SBERJAZZ_CB_OPEN_SEC:-60}
      SBERJAZZ_OP_LOCK_TTL_SEC: ${SBERJAZZ_OP_LOCK_TTL_SEC:-60}
      SBERJAZZ_CB_AUTO_RESET_ENABLED: ${SBERJAZZ_CB_AUTO_RESET_ENABLED:-true}
      SBERJAZZ_CB_AUTO_RESET_MIN_AGE_SEC: ${SBERJAZZ_CB_AUTO_RESET_MIN_AGE_SEC:-30}
      SBERJAZZ_SESSION_TTL_SEC: ${SBERJAZZ_SESSION_TTL_SEC:-86400}
      SBERJAZZ_RECONCILE_STALE_SEC: ${SBERJAZZ_RECONCILE_STALE_SEC:-900}
      SBERJAZZ_LIVE_PULL_ENABLED: ${SBERJAZZ_LIVE_PULL_ENABLED:-true}
      SBERJAZZ_LIVE_PULL_BATCH_LIMIT: ${SBERJAZZ_LIVE_PULL_BATCH_LIMIT:-20}
      SBERJAZZ_LIVE_PULL_SESSIONS_LIMIT: ${SBERJAZZ_LIVE_PULL_SESSIONS_LIMIT:-100}
      SBERJAZZ_LIVE_PULL_RETRIES: ${SBERJAZZ_LIVE_PULL_RETRIES:-1}
      SBERJAZZ_LIVE_PULL_RETRY_BACKOFF_MS: ${SBERJAZZ_LIVE_PULL_RETRY_BACKOFF_MS:-200}
      SBERJAZZ_MOCK_LIVE_CHUNKS_B64: ${SBERJAZZ_MOCK_LIVE_CHUNKS_B64:-}
      RECONCILIATION_ENABLED: ${RECONCILIATION_ENABLED:-true}
      RECONCILIATION_INTERVAL_SEC: ${RECONCILIATION_INTERVAL_SEC:-60}
      RECONCILIATION_LIMIT: ${RECONCILIATION_LIMIT:-200}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      LOG_FORMAT: ${LOG_FORMAT:-json}
    command: ["python3", "-m", "apps.worker_reconciliation.main"]
    volumes:
      - app_data:/data
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:v2.54.1
    profiles: ["observability"]
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.enable-lifecycle"
    volumes:
      - ./ops/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./ops/prometheus_alerts.yml:/etc/prometheus/prometheus_alerts.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    depends_on:
      api-gateway:
        condition: service_started
    restart: unless-stopped

  alertmanager:
    image: prom/alertmanager:v0.27.0
    profiles: ["observability"]
    command:
      - "--config.file=/etc/alertmanager/alertmanager.yml"
    volumes:
      - ./ops/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
    ports:
      - "9093:9093"
    restart: unless-stopped

  grafana:
    image: grafana/grafana:11.2.0
    profiles: ["observability"]
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin}
    volumes:
      - ./ops/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./ops/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana_data:/var/lib/grafana
    ports:
      - "3000:3000"
    depends_on:
      prometheus:
        condition: service_started
    restart: unless-stopped

volumes:
  pg_data:
  redis_data:
  app_data:
  hf_cache:
  prometheus_data:
  grafana_data:
